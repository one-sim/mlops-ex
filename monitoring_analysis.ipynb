{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ef0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Test unitari della funzione principale (esempi)\n",
    "# Esegue un set di test rapidi per verificare logger, metrics, drift e retraining\n",
    "\n",
    "from src.monitoring import PredictionLogger\n",
    "from src.metrics import MetricsTracker\n",
    "from src.drift_detection import DriftDetector\n",
    "from src.retraining import RetrainingManager\n",
    "from datetime import datetime\n",
    "\n",
    "# Test 1: Logging corretto\n",
    "pl = PredictionLogger(log_dir='logs')\n",
    "pl.clear_logs()\n",
    "res = {'Positivo': 0.9, 'Neutro': 0.09, 'Negativo': 0.01}\n",
    "entry = pl.log_prediction('Test logging', res)\n",
    "assert pl.get_logs_count() >= 1\n",
    "print('Test 1 passed: logging corretto')\n",
    "\n",
    "# Test 2: Metrics aggregation\n",
    "mt = MetricsTracker(metrics_dir='logs')\n",
    "logs = pl.load_logs()\n",
    "metrics = mt.calculate_metrics(logs)\n",
    "assert metrics.total_predictions >= 1\n",
    "print('Test 2 passed: metrics aggregation')\n",
    "\n",
    "# Test 3: Drift detection con distribuzioni artificiali\n",
    "from src.monitoring import PredictionLog\n",
    "fake_logs = [\n",
    "    PredictionLog(timestamp=datetime.now().isoformat(), text='t1', sentiment='Positivo', confidence=0.9, scores={'Positivo':0.9,'Neutro':0.08,'Negativo':0.02})\n",
    "    for _ in range(60)\n",
    "]\n",
    "\n",
    "det = DriftDetector(baseline_file='logs/baseline_test.json', metrics_dir='logs', drift_threshold=0.1)\n",
    "det.set_baseline(fake_logs[:30])\n",
    "report = det.detect_drift(fake_logs[30:])\n",
    "print('Test 3 passed: drift detection eseguito', report.drift_detected)\n",
    "\n",
    "# Test 4: Retraining trigger\n",
    "rm = RetrainingManager(min_samples_for_retraining=10, confidence_threshold=0.95, drift_detector=det, metrics_dir='logs')\n",
    "trigger = rm.evaluate_retraining_need(fake_logs)\n",
    "print('Test 4 passed: retraining evaluated', trigger.triggered)\n",
    "\n",
    "print('✅ Tutti i test rapidi sono stati eseguiti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c816ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Visualizzare Distribuzioni Sentiment nel tempo\n",
    "\n",
    "# Calcola metriche su finestre orarie\n",
    "metrics_over_time = metrics_tracker.get_metrics_over_time(logger.load_logs(), window_hours=1)\n",
    "\n",
    "# Prepara i dati per il plotting\n",
    "if metrics_over_time:\n",
    "    timestamps = [t for t, m in metrics_over_time]\n",
    "    positives = [m.sentiment_distribution.get('Positivo', 0) for t, m in metrics_over_time]\n",
    "    neutrals = [m.sentiment_distribution.get('Neutro', 0) for t, m in metrics_over_time]\n",
    "    negatives = [m.sentiment_distribution.get('Negativo', 0) for t, m in metrics_over_time]\n",
    "\n",
    "    plt.plot(timestamps, positives, label='Positivo')\n",
    "    plt.plot(timestamps, neutrals, label='Neutro')\n",
    "    plt.plot(timestamps, negatives, label='Negativo')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.title('Evoluzione distribuzione sentiment nel tempo (finestre orarie)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Non ci sono abbastanza dati per mostrare metriche nel tempo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Valutare Modello su Test Set\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Usa un campione del test set per la valutazione\n",
    "sample_size = min(200, len(dataset['test']))\n",
    "indices = np.random.choice(len(dataset['test']), sample_size, replace=False)\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "confs = []\n",
    "\n",
    "for i in indices:\n",
    "    sample = dataset['test'][int(i)]\n",
    "    text = sample['text']\n",
    "    true_label = label_mapping[sample['label']]\n",
    "    res = analyze_sentiment(text)\n",
    "    pred_label = max(res, key=res.get)\n",
    "    conf = res[pred_label]\n",
    "\n",
    "    preds.append(pred_label)\n",
    "    trues.append(true_label)\n",
    "    confs.append(conf)\n",
    "\n",
    "# Mappa a valori numerici\n",
    "label_to_idx = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "y_true = [label_to_idx[t] for t in trues]\n",
    "y_pred = [label_to_idx[p] for p in preds]\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"EVALUATION\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 (weighted): {f1:.4f}\")\n",
    "print(f\"Precision (weighted): {precision:.4f}\")\n",
    "print(f\"Recall (weighted): {recall:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(label_mapping.values()))\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Distribuzione confidenza\n",
    "sns.histplot(confs, bins=20)\n",
    "plt.title('Distribuzione dei confidence score')\n",
    "plt.xlabel('Confidence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ecce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Implementare Trigger Retraining\n",
    "\n",
    "logs = logger.load_logs()\n",
    "trigger = retraining_manager.evaluate_retraining_need(logs)\n",
    "retraining_manager.save_trigger(trigger)\n",
    "\n",
    "print(\"Retraining trigger:\")\n",
    "print(json.dumps(trigger.to_dict(), indent=2))\n",
    "\n",
    "if trigger.triggered:\n",
    "    print(\"✅ Trigger per retraining attivato: \", trigger.recommended_action)\n",
    "else:\n",
    "    print(\"Nessun retraining necessario al momento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e510fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Implementare Drift Detection\n",
    "\n",
    "logs = logger.load_logs()\n",
    "report = drift_detector.detect_drift(logs)\n",
    "\n",
    "drift_detector.save_drift_report(report)\n",
    "\n",
    "print(\"Drift report:\")\n",
    "print(json.dumps(report.to_dict(), indent=2))\n",
    "\n",
    "if report.drift_detected:\n",
    "    print(\"⚠️ Drift rilevato — considerare il retraining\")\n",
    "else:\n",
    "    print(\"No drift rilevato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd54261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Calcolare Metriche Aggregate\n",
    "\n",
    "logs = logger.load_logs()\n",
    "metrics = metrics_tracker.calculate_metrics(logs)\n",
    "metrics_tracker.save_metrics(metrics)\n",
    "\n",
    "print(\"Metriche aggregate:\")\n",
    "print(json.dumps(metrics.to_dict(), indent=2))\n",
    "\n",
    "# Mostra distribuzione sentiment\n",
    "sns.barplot(\n",
    "    x=list(metrics.sentiment_distribution.keys()),\n",
    "    y=list(metrics.sentiment_distribution.values())\n",
    ")\n",
    "plt.title(\"Distribuzione dei sentiment (campione)\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Conteggio\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Confidenza media: {metrics.average_confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Implementare Prediction Logger (esempio d'uso)\n",
    "# Esegui inferenze su un campione e logga le predizioni\n",
    "import numpy as np\n",
    "\n",
    "sample_size: int = 100\n",
    "indices = np.random.choice(len(dataset['test']), sample_size, replace=False)\n",
    "\n",
    "for i in indices:\n",
    "    sample = dataset['test'][int(i)]\n",
    "    text = sample['text']\n",
    "    true_label = label_mapping[sample['label']]\n",
    "    \n",
    "    scores = analyze_sentiment(text)\n",
    "    pred_label = max(scores, key=scores.get)\n",
    "    \n",
    "    logger.log_prediction(text=text, sentiment_scores=scores)\n",
    "\n",
    "print(f\"✅ Loggate {logger.get_logs_count()} predizioni di esempio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a03a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Scaricare e Caricare il Dataset\n",
    "# Carica il dataset\n",
    "dataset = load_dataset(\"tweet_eval\", \"sentiment\")\n",
    "\n",
    "# Mapping delle label\n",
    "label_mapping: Dict[int, str] = {0: \"Negativo\", 1: \"Neutro\", 2: \"Positivo\"}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train samples: {len(dataset['train'])}\")\n",
    "print(f\"Test samples: {len(dataset['test'])}\")\n",
    "print(f\"Label mapping: {label_mapping}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a6a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Configurare il Sistema di Logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Crea le directory necessarie\n",
    "logs_dir: Path = Path(\"logs\")\n",
    "logs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Inizializza i componenti del sistema di monitoraggio\n",
    "logger: PredictionLogger = PredictionLogger(log_dir=\"logs\")\n",
    "metrics_tracker: MetricsTracker = MetricsTracker(metrics_dir=\"logs\")\n",
    "drift_detector: DriftDetector = DriftDetector(\n",
    "    baseline_file=\"logs/baseline_distribution.json\",\n",
    "    drift_threshold=0.15,\n",
    "    metrics_dir=\"logs\"\n",
    ")\n",
    "retraining_manager: RetrainingManager = RetrainingManager(\n",
    "    min_samples_for_retraining=50,\n",
    "    confidence_threshold=0.70,\n",
    "    drift_detector=drift_detector,\n",
    "    metrics_dir=\"logs\"\n",
    ")\n",
    "\n",
    "# Pulisci i log precedenti (opzionale)\n",
    "logger.clear_logs()\n",
    "metrics_tracker.clear_metrics()\n",
    "drift_detector.clear_drift_reports()\n",
    "retraining_manager.clear_triggers()\n",
    "\n",
    "print(\"✅ Sistema di logging configurato\")\n",
    "print(f\"Directory dei log: {logs_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d85d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importare Librerie Necessarie\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Librerie di visualizzazione\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn per le metriche\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Modelli locali\n",
    "sys.path.insert(0, '/workspaces/mlops-ex')\n",
    "from src.sentiment_model import analyze_sentiment\n",
    "from src.monitoring import PredictionLogger, PredictionLog\n",
    "from src.metrics import MetricsTracker, SentimentMetrics\n",
    "from src.drift_detection import DriftDetector, DriftReport\n",
    "from src.retraining import RetrainingManager, RetrainingTrigger\n",
    "\n",
    "# Configurazione di stile\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✅ Tutte le librerie importate correttamente\")\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a376a57d",
   "metadata": {},
   "source": [
    "# MLOps Sentiment Analysis - Sistema di Monitoraggio Completo\n",
    "\n",
    "Questo notebook implementa il sistema completo di monitoraggio e retraining per il modello di sentiment analysis. Include:\n",
    "- ✅ Download del dataset\n",
    "- ✅ Valutazione del modello su test set (Accuracy, F1-Score)\n",
    "- ✅ Logging delle predizioni con timestamp\n",
    "- ✅ Tracking delle metriche (distribuzione sentiment, confidence media)\n",
    "- ✅ Rilevazione del drift confrontando con baseline\n",
    "- ✅ Trigger di retraining basato su performance\n",
    "- ✅ Visualizzazioni dei risultati\n",
    "- ✅ Test unitari della funzione principale"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
